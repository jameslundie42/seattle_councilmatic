# Seattle Councilmatic

A website for tracking Seattle City Council legislation, built on the [Councilmatic](https://www.councilmatic.org/) platform.

## ğŸ¯ What It Does

Seattle Councilmatic makes it easy to:

- Find your Seattle City Council representative
- Track legislation (bills, resolutions, ordinances)
- See upcoming council meetings and agendas
- Follow votes on issues you care about

**Live site:** <http://localhost:8000> (development)

---

## ğŸ—ï¸ Architecture

### Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  seattle.gov    â”‚  Official city council website
â”‚  legistar.com   â”‚  Legislative management system
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Scrapers pull data
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pupa Scrapers  â”‚  Extract & Transform data
â”‚  (seattle/)     â”‚  
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Writes to OCD format
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL     â”‚  Open Civic Data models
â”‚  + PostGIS      â”‚  (opencivicdata_*)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Synced to
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Councilmatic    â”‚  Django models
â”‚   Models        â”‚  (councilmatic_core_*)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Indexed by
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Elasticsearch   â”‚  Full-text search
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Powers
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Django Web UI  â”‚  User-facing website
â”‚  (seattle_app/) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure

```
seattle-councilmatic/
â”œâ”€â”€ seattle/              # Pupa scrapers (data collection)
â”‚   â”œâ”€â”€ __init__.py      # Jurisdiction definition
â”‚   â”œâ”€â”€ people.py        # Council member scraper
â”‚   â”œâ”€â”€ events.py        # Meeting scraper (TODO)
â”‚   â””â”€â”€ bills.py         # Legislation scraper (TODO)
â”œâ”€â”€ seattle_app/         # Django application (presentation)
â”‚   â”œâ”€â”€ management/      # Custom management commands
â”‚   â”œâ”€â”€ templates/       # HTML templates
â”‚   â”œâ”€â”€ static/          # CSS, JS, images
â”‚   â”œâ”€â”€ models.py        # Custom model extensions
â”‚   â””â”€â”€ settings.py      # Django configuration
â”œâ”€â”€ scripts/             # Helper scripts
â”‚   â””â”€â”€ update_seattle.sh # One-command data update
â”œâ”€â”€ docker-compose.yml   # Container orchestration
â”œâ”€â”€ Dockerfile           # Container definition
â””â”€â”€ requirements.txt     # Python dependencies
```

---

## ğŸš€ Getting Started

### Prerequisites

- [Docker Desktop](https://docs.docker.com/desktop/)
- Git

### Initial Setup

1. **Clone the repository:**

```bash
   git clone [your-repo-url]
   cd seattle-councilmatic
```

2. **Configure environment:**

```bash
   cp .env.example .env
   # Edit .env and add your DJANGO_SECRET_KEY
   # Generate one with: python -c 'from django.core.management.utils import get_random_secret_key; print(get_random_secret_key())'
```

3. **Build containers:**

```bash
   docker compose build
```

4. **Initialize database:**

```bash
   # Run Django migrations
   docker compose run --rm app python manage.py migrate
   
   # Initialize Pupa tables
   docker compose run --rm app pupa dbinit us
   
   # Create admin user
   docker compose run --rm app python manage.py createsuperuser
```

5. **Load initial data:**

```bash
   docker compose run --rm app ./scripts/update_seattle.sh
```

6. **Start the application:**

```bash
   docker compose up
```

7. **Visit the site:**
   - Main site: <http://localhost:8000>
   - Admin: <http://localhost:8000/admin>

---

## ğŸ”„ Daily Development Workflow

### Update Data

```bash
# Full update (all scrapers)
docker compose run --rm app ./scripts/update_seattle.sh

# Update specific scraper
docker compose run --rm app ./scripts/update_seattle.sh people
```

### View Logs

```bash
# All services
docker compose logs -f

# Specific service
docker compose logs -f app
docker compose logs -f webpack
```

### Django Management Commands

```bash
# Run any Django command
docker compose run --rm app python manage.py [command]

# Examples:
docker compose run --rm app python manage.py shell
docker compose run --rm app python manage.py dbshell
docker compose run --rm app python manage.py sync_councilmatic
```

### Restart Services

```bash
# Restart all
docker compose restart

# Restart specific service
docker compose restart app
```

---

## ğŸ› ï¸ Technical Details

### Data Flow

1. **Scraping** (`pupa update seattle`)
   - Scrapers in `seattle/` fetch data from source websites
   - Data is validated and cached locally
   - Written to OpenCivicData tables (`opencivicdata_*`)

2. **Syncing** (`python manage.py sync_councilmatic`)
   - Bridges OCD models â†’ Councilmatic models
   - Handles multi-table inheritance pattern
   - Creates required fields (slugs, etc.)

3. **Indexing** (`python manage.py update_index`)
   - Populates Elasticsearch for full-text search
   - Powers the site's search functionality

### Why Two Sets of Models?

Django-councilmatic 5.x uses **multi-table inheritance** rather than proxy models:

- **OCD Models** (`opencivicdata_person`): Canonical data from scrapers
- **Councilmatic Models** (`councilmatic_core_person`): Extended with web-specific fields (slugs, headshots, etc.)

They're linked via foreign key, requiring the sync step.

### Important Settings

**In `seattle_app/settings.py`:**

```python
# Must match your Jurisdiction.name in seattle/__init__.py
OCD_CITY_COUNCIL_NAME = 'Seattle City Council'

# Both scraper and app must be in INSTALLED_APPS
INSTALLED_APPS = [
    # ...
    'opencivicdata.core.apps.BaseConfig',
    'councilmatic_core',
    'seattle_app',  # Django app
    'seattle',      # Pupa scrapers
]
```

---

## ğŸ§ª Testing

### Run Tests

```bash
docker compose run --rm app python manage.py test
```

### Check Scraper Output

```bash
# Scrape without importing (for testing)
docker compose run --rm app pupa update seattle people --scrape

# Check what was scraped
docker compose run --rm app ls -la _data/
```

### Validate Data

```bash
docker compose run --rm app python manage.py shell
```

```python
from opencivicdata.core.models import Person, Organization
from councilmatic_core.models import Person as CouncilPerson

# Check data counts
print(f"OCD People: {Person.objects.count()}")
print(f"Councilmatic People: {CouncilPerson.objects.count()}")
print(f"Organizations: {Organization.objects.count()}")

# Verify memberships
council = Organization.objects.get(name='Seattle City Council')
print(f"Council members: {council.memberships.count()}")
```

---

## ğŸ› Troubleshooting

### "No data showing on website"

1. Check if data exists in database:

```bash
   docker compose run --rm app python manage.py shell -c "from opencivicdata.core.models import Person; print(Person.objects.count())"
```

2. Run sync command:

```bash
   docker compose run --rm app python manage.py sync_councilmatic
```

3. Rebuild search index:

```bash
   docker compose run --rm app python manage.py rebuild_index --noinput
```

### "Containers won't start"

Check port conflicts:

```bash
# Check if ports are in use
lsof -i :8000  # Django
lsof -i :5432  # PostgreSQL
lsof -i :9200  # Elasticsearch
lsof -i :3000  # Webpack
```

### "Out of memory errors"

Increase Docker Desktop memory allocation:

- Settings â†’ Resources â†’ Memory â†’ Set to at least 4GB

### "Database migrations fail"

Reset and re-initialize:

```bash
docker compose down -v  # WARNING: Deletes all data!
docker compose up -d postgres
docker compose run --rm app python manage.py migrate
docker compose run --rm app pupa dbinit us
```

---

## ğŸ“š Key Documentation Links

- [Councilmatic Website](https://www.councilmatic.org/)
- [Open Civic Data & Pupa Documentation](https://open-civic-data.readthedocs.io/en/latest/)
- [Open Civic Data Github](https://github.com/opencivicdata)
- [Django Documentation](https://docs.djangoproject.com/)

---

## ğŸ¤ Contributing

### Adding New Scrapers

1. **Create scraper file** in `seattle/` (e.g., `events.py`)

2. **Register in jurisdiction** (`seattle/__init__.py`):

```python
   from .events import SeattleEventScraper
   
   class Seattle(Jurisdiction):
       scrapers = {
           "people": SeattlePersonScraper,
           "events": SeattleEventScraper,  # Add here
       }
```

3. **Test the scraper:**

```bash
   docker compose run --rm app pupa update seattle events --scrape
```

4. **Run full import:**

```bash
   docker compose run --rm app ./scripts/update_seattle.sh events
```

### Code Style

- Follow PEP 8 for Python
- Use Django conventions
- Add docstrings to functions
- Comment complex logic

---

## ğŸ“ License

[Your chosen license]

---

## ğŸ™ Acknowledgments

Built with:

- [Councilmatic](https://www.councilmatic.org/) by DataMade
- [Open Civic Data](https://opencivicdata.org/)
- [Pupa](https://github.com/opencivicdata/pupa) scraping framework

Data sources:

- [Seattle City Council](https://www.seattle.gov/council)
- [Seattle Legistar](https://seattle.legistar.com)
